<h1 id="deep-learning-related-topics">Deep Learning Related Topics</h1>
<h2 id="resnext">ResNeXt</h2>
<blockquote>
<p>ä¼ ç»Ÿä¸ºå¢åŠ æ·±åº¦ï¼ˆå±‚æ•°ï¼‰å’Œå®½åº¦ï¼ˆç‰¹å¾ç»´åº¦ï¼‰ï¼Œå˜æˆç»“åˆVGGçš„å †å ç½‘ç»œ+Inceptionçš„ <em>split-transform-merge</em> ç­–ç•¥ã€‚å¢åŠ å‡†ç¡®ç‡å’Œå¯æ‰©å±•æ€§åŒæ—¶ä¸æ”¹å˜æˆ–å‡å°å¤æ‚åº¦  </p>
</blockquote>
<p>æå‡º<u><strong>cardinality</strong></u>ï¼Œè¡¨ç¤ºå¤šåˆ†æ”¯çš„åˆ†æ”¯æ•°é‡ï¼Œmore effective<br><img src="Figures/EC005B55-327B-4F4C-A5FE-9232BA9D04E8.png" alt=""><br>ğŸ‘†å·¦ä¸ºResNetï¼Œå³ä¸ºResNeXt cardinality=32<br><u><strong>å¹³è¡Œå †å </strong></u>ä»£æ›¿çº¿æ€§åŠ æ·±ï¼Œä¸æ˜¾è‘—å¢åŠ å‚æ•°æ•°é‡çº§å¢åŠ å‡†ç¡®ç‡ï¼›åŒæ—¶å¹³è¡Œåˆ†æ”¯çš„æ‹“æ‰‘ç»“æ„ç›¸åŒå‡å°‘äº†è¶…å‚æ•°ï¼ˆè®¾è®¡æˆæœ¬ï¼‰<br><img src="Figures/C1CCACF2-6F03-4B74-99C6-E8397306F05E.png" alt=""><br>ğŸ‘†split-transform-mergeè¿‡ç¨‹<br><img src="Figures/E210EA79-5D84-4C33-B0BA-146AFABB08A2.png" alt=""><br>ğŸ‘†ä¸‰ç§ç­‰ä»·çš„ç»“æ„ï¼Œç¬¬ä¸‰ç§ç®€æ´ï¼Œé€Ÿåº¦æ›´å¿«</p>
<hr>
<h2 id="-">å·ç§¯å¤§å°</h2>
<p><img src="https://latex.codecogs.com/svg.latex?O=\lfloor\frac{W-F+2P}{S}\rfloor+1" alt="latex_equ"></p>
<p><strong>Dilated Conv</strong></p>
<p><img src="https://latex.codecogs.com/svg.latex?O=\frac{W+2P-%28d%28k-1%29+1%29}{S}+1" alt="latex_equ"></p>
<h2 id="mobilenet">MobileNet</h2>
<p>æŠŠä¼ ç»Ÿå·ç§¯å˜æˆdepth-wiseå·ç§¯å’Œ1x1å·ç§¯<br>æ ‡å‡†å·ç§¯ï¼ˆDkå·ç§¯æ ¸å¤§å°ï¼ŒDfè¾“å‡ºç‰¹å¾å›¾å°ºå¯¸ï¼ŒMè¾“å…¥é€šé“ï¼ŒNè¾“å‡ºé€šé“ï¼‰<br><img src="https://latex.codecogs.com/svg.latex?D_K\times%20D_K\times%20M\times%20N\times%20D_F\times%20D_F" alt="latex_equ"><br><strong>æ·±åº¦å¯åˆ†ç¦»å·ç§¯</strong>ï¼šdepth-wiseå·ç§¯å’Œ<code>1x1</code>å·ç§¯</p>
<p><img src="https://latex.codecogs.com/svg.latex?D_K\times%20D_K\times%20M\times%20D_F\times%20D_F%20+%20M\times%20N\times%20D_F\times%20D_F" alt="latex_equ"></p>
<p>Depthå·ç§¯æŠŠè¾“å…¥ç‰¹å¾å›¾Dk x Dk x MæˆDf x Df x Må±‚ï¼Œç„¶å<code>1x1</code>æŠŠMå±‚å˜ä¸ºNå±‚è¾“å‡º<br><img src="Figures/6B22C4FC-30D7-45C9-9CD8-DD3469070EDC.png" alt=""><br>ğŸ‘†<u><strong>depth-wise conv</strong></u>ä¸åŒç‰¹å¾å›¾é€šé“ä½¿ç”¨ä¸åŒå·ç§¯æ ¸ï¼ŒMå±‚ç‰¹å¾å›¾å·ç§¯è¿˜æ˜¯Må±‚ï¼ˆä¸ç›¸åŠ ï¼‰æ‰€ä»¥<code>Dk x Dk x M x Df x Df</code>ï¼ˆä¸€ä¸ªå·ç§¯æ ¸è®¡ç®—<code>Dk x Dk</code>æ¬¡ï¼Œæ„æˆè¾“å‡ºç‰¹å¾å›¾çš„ä¸€ä¸ªç‚¹ï¼Œæ‰€ä»¥ä¸€å¼ è¾“å‡ºç‰¹å¾å›¾ä¸€å…±è®¡ç®—<code>Dk x Dk x Df x Df</code>æ¬¡ï¼Œä¸€å…±Må±‚ï¼‰<br><img src="Figures/770C8B8D-2E90-4D9E-99D4-E1BE24CAE3A4.png" alt=""><br>ğŸ‘†depth-wiseè§£é‡Š<br><img src="Figures/C8B12662-17AF-4AE3-8753-17E1F0A5FAC0.png" alt=""><br>ğŸ‘†<u><strong>point-wise conv</strong></u>ä¸åŒç‰¹å¾å›¾ä½¿ç”¨åŒä¸€ä¸ªå·ç§¯æ ¸ï¼Œä½†æ˜¯1x1ã€‚æŠŠMé€šé“å·ç§¯æˆNé€šé“ï¼Œæ‰€ä»¥<code>M x N x Df x Df</code> ï¼ˆä¸€ä¸ªå·ç§¯æ ¸è®¡ç®—Må±‚ç›¸åŠ ï¼Œå†è®¡ç®—Næ¬¡æ„æˆNé€šé“ï¼‰<br><img src="Figures/B1AE5F5A-4B07-4A4E-A1F3-932F477265B7.png" alt=""><br>ğŸ‘†point-wiseè§£é‡Š</p>
<hr>
<h2 id="convolution">Convolution</h2>
<p><img src="Figures/B712984B-A621-4D75-B9C1-7DB0D7D0226F.png" alt=""><br><img src="Figures/4ECAAE30-D4AB-45FC-A130-F8DE831CC235.png" alt=""><br>å‚æ•°é‡ <code>H x W x C1 x C2</code></p>
<h2 id="group-convolution">Group Convolution</h2>
<p><img src="Figures/FB2404B4-04DF-4E98-923F-0E5DDB739C0A.png" alt=""><br>å·ç§¯æ ¸ä¹‹é—´çš„å…³ç³»æ˜¯<strong>ç¨€ç–</strong>çš„ã€‚group convå‡å°‘å·ç§¯æ ¸ä¹‹é—´çš„å…³è”æ€§ï¼Œ <strong>regularization</strong>ï¼Œå‡å°‘è¿‡æ‹Ÿåˆ<br>Ref: <a href="https://blog.yani.io/filter-group-tutorial/">A Tutorial on Filter Groups (Grouped Convolution) - A Shallow Blog about Deep Learning</a></p>
<hr>
<h2 id="mobilenet-v2">MobileNet V2</h2>
<p>å¢åŠ <u><strong>inverted residual with linear bottleneck</strong></u>ï¼Œé¦–å…ˆå‡ç»´ï¼Œå·ç§¯ï¼Œå†é™ç»´ã€‚ <u>ç‰¹å¾æå–åœ¨é«˜ç»´ç©ºé—´è¿›è¡Œ</u> ã€‚çººé”¤å½¢ï¼Œå’Œresnetçš„hour-glassç›¸åï¼Œæ‰€ä»¥inverted<br>åœ¨DWä¹‹å‰ <u><strong>å¢åŠ PWå·ç§¯</strong></u>ï¼šä¸Šä¸€å±‚é€šé“æ•°å°‘ï¼Œåˆ™DWåªèƒ½åœ¨ä½ç»´ç©ºé—´æå–ç‰¹å¾ï¼Œå¢åŠ PWåï¼Œå…ˆå‡ç»´ï¼Œå†æDWç‰¹å¾<br><img src="Figures/20A1CAA2-880C-4C27-9475-C66CC955FDA5.png" alt=""><br>å»æ‰äº†ç¬¬äºŒä¸ªPWçš„ <u><strong>æ¿€æ´»å‡½æ•°</strong></u> ï¼šåªæœ‰åœ¨é«˜ç»´ç©ºé—´ä¸­ï¼Œæ¿€æ´»å‡½æ•°å¯ä»¥å¢åŠ éçº¿æ€§ï¼›è€Œåœ¨ä½ç»´ç©ºé—´ä¸­ï¼Œæ¿€æ´»å‡½æ•°ä¼šç ´åç‰¹å¾ã€‚å› æ­¤é‡‡ç”¨çº¿æ€§<br>å¢åŠ  <strong>shortcut</strong> è¿æ¥ï¼Œè¾“å‡ºä¸è¾“å…¥ç›¸åŠ ï¼šåŒResNet</p>
<hr>
<h2 id="shufflenet">ShuffleNet</h2>
<blockquote>
<p>ç»„å†…point-wiseå·ç§¯ï¼Œå¢åŠ shuffleæ“ä½œé€šé“ä¹‹é—´ä¿¡æ¯æ²Ÿé€š  </p>
</blockquote>
<p><img src="Figures/B747E511-B1B6-4CD8-9F8F-446708466A2B.png" alt=""><br>ğŸ‘†aï¼šnormalï¼Œbï¼šåˆ†ç»„å·ç§¯ï¼Œcï¼šchannel shuffle</p>
<p><em>å¦ä¸€ç§ç†è§£ğŸ‘‡</em></p>
<p><img src="Figures/image-20200322164220501.png" alt="image-20200322164220501"></p>
<h4 id="channel-shuffle">Channel shuffle</h4>
<p>ğŸ‘‡<u><strong>å±•å¼€ï¼Œè½¬ç½®ï¼Œå¹³é“º</strong></u><br><img src="Figures/6C36658F-B3E1-4407-9517-D585F622C5BE.png" alt=""><br><img src="Figures/3C97825C-0822-455C-AB65-9D0E27EB706C.png" alt=""><br>ğŸ‘†å¯¹æ¯”mobilenetï¼Œshufflenetå’Œshuffleneté™é‡‡æ ·<br>ğŸ‘†gé‡‡ç”¨åˆ†ç»„å·ç§¯ï¼Œgå°ï¼›å»æ‰ReLUï¼Œå‡å°‘ä¿¡æ¯æŸè€—ï¼›é™é‡‡æ ·ä¿è¯å‚æ•°é‡ä¸éª¤å‡ï¼Œéœ€è¦å¢åŠ é€šé“æ•°é‡ï¼Œé‡‡ç”¨concatè€Œä¸æ˜¯element-wise add<br><strong>æ€§èƒ½è¯„ä»·</strong>ï¼šMACè®¿å­˜ï¼ŒGPUå¹¶è¡Œæ€§<br><strong>è®¾è®¡å‡†åˆ™</strong></p>
<ul>
<li>å½“è¾“å…¥é€šé“æ•°å’Œè¾“å‡ºé€šé“æ•°ç›¸åŒæ—¶ï¼ŒMACæœ€å°</li>
<li>MACä¸åˆ†ç»„æ•°é‡gæˆæ­£æ¯”ï¼ˆè°¨æ…ä½¿ç”¨åˆ†ç»„å·ç§¯ï¼‰</li>
<li>ç½‘ç»œçš„åˆ†æ”¯æ•°é‡é™ä½å¹¶è¡Œèƒ½åŠ›ï¼ˆå·ç§¯æ ¸åŠ è½½å’ŒåŒæ­¥ï¼‰ï¼Œå•åˆ†æ”¯é€Ÿåº¦å¿«--ç½‘ç»œç»“æ„ç®€å•<ul>
<li>ResNeXtå‡†ç¡®ç‡æå‡ä½†æ˜¯é€Ÿåº¦æ…¢</li>
</ul>
</li>
<li>Element-wiseæ“ä½œæ˜¯éå¸¸è€—æ—¶</li>
</ul>
<p><img src="Figures/EA15DE00-DC00-4A95-B656-20AA985E0269.png" alt=""><br>ğŸ‘†shufflenet v2å’Œdownsample<br>å¢åŠ <strong>é€šé“åˆ†å‰²</strong>ï¼Œé€šé“åˆ†ä¸ºc1å’Œc2è¾“å…¥åˆ°ä¸¤ä¸ªåˆ†æ”¯ä¸­ï¼Œä½¿ç”¨concatæ›¿ä»£element-wise add<br>å †å blockçš„æ—¶å€™ï¼Œå¯ä»¥å°†concat, channel-shuffle, channel-splitåˆå¹¶ä¸ºä¸€ä¸ªelement-wiseæ“ä½œ<br>æ€æƒ³â€”<u><strong>ç‰¹å¾é‡ç”¨</strong></u>ï¼Œä¸Šå±‚çš„feature mapç›´æ¥ä¼ å…¥ä¹‹åçš„æ¨¡å—ï¼Œç›´æ¥æ˜ å°„ï¼ˆshufflenet v2å·¦ä¾§åˆ†æ”¯ï¼‰</p>
<hr>
<h2 id="squeezenet">SqueezeNet</h2>
<blockquote>
<p><u><strong>åˆ†å—è®¾è®¡</strong></u>æ€æƒ³ï¼Œæ¨¡å‹<u><strong>å‹ç¼©</strong></u></p>
</blockquote>
<ol>
<li>ä½¿ç”¨<code>1x1</code>å·ç§¯ä»£æ›¿<code>3x3</code>å·ç§¯  </li>
<li>å‡å°‘<code>3x3</code>å·ç§¯è¾“å…¥é€šé“æ•°  </li>
<li>å»¶è¿Ÿä¸‹é‡‡æ ·ï¼Œå‰é¢layerè·å¾—æ›´å¤§ç‰¹å¾å›¾æå‡æ€§èƒ½  </li>
</ol>
<p><strong>Fire Module</strong></p>
<p>ä¸¤å±‚å·ç§¯æ“ä½œï¼šsqueeze <code>1x1</code>, expand <code>1x1 + 3x3</code><br><img src="Figures/v2-5fde12f060519e493cb059484514f88a_hd.jpg" alt=""><br>ğŸ‘†ğŸ‘‡ <u>squeezeæ˜¯å•åˆ†æ”¯ï¼Œexpandæ˜¯äºŒåˆ†æ”¯</u><br><img src="Figures/1DCBEDA4-1CA7-4029-8E78-BF80ABEF9898.png" alt=""><br>éƒ¨åˆ†3x3å˜æˆ1x1ï¼Œå‚æ•°æ•°é‡å‡å°‘ï¼Œä½†ä¸ºè·å¾—æ€§èƒ½éœ€è¦åŠ æ·±ç½‘ç»œæ·±åº¦ï¼ŒåŒæ—¶å¹¶è¡Œèƒ½åŠ›ä¸‹é™ï¼Œä¹Ÿå¯¼è‡´æµ‹è¯•æ—¶é—´å˜é•¿<br><img src="Figures/v2-5f8ff8cb94babde05e69365336e77a62_hd.jpg" alt=""><br>ğŸ‘†ç½‘ç»œç»“æ„</p>
<hr>
<h2 id="squeeze-and-excitation-networks">Squeeze-and-Excitation Networks</h2>
<p><a href="https://www.arxiv.org/pdf/1709.01507.pdf">arXiv</a><br>å·ç§¯æ ¸ï¼šç©ºé—´ç»´åº¦ä¿¡æ¯ï¼Œç‰¹å¾ç»´åº¦ä¿¡æ¯èšé›†<br>ç©ºé—´spatialï¼šinception(multiscale)ï¼Œinside-outside(context)<br>SENet-&gt;ç‰¹å¾ç»´åº¦,feature channel<br>Motivation:</p>
<ol>
<li>Explicitly model channel-interdependcies</li>
<li>Feature recalibration: enhance useful, suppress less useful</li>
</ol>
<p>ç‰¹å¾é€šé“ä¹‹é—´çš„å…³ç³»ï¼šç‰¹å¾é‡æ ‡å®šï¼ˆé€šè¿‡å­¦ä¹ çš„æ–¹å¼æ¥è‡ªåŠ¨è·å–åˆ°æ¯ä¸ªç‰¹å¾é€šé“çš„é‡è¦ç¨‹åº¦ï¼Œç„¶åä¾ç…§è¿™ä¸ªé‡è¦ç¨‹åº¦å»æå‡æœ‰ç”¨çš„ç‰¹å¾å¹¶æŠ‘åˆ¶å¯¹å½“å‰ä»»åŠ¡ç”¨å¤„ä¸å¤§çš„ç‰¹å¾ï¼‰<br>Squeeze: global pooling, é¡ºç€ç©ºé—´ç»´åº¦å‹ç¼©ï¼Œå¢åŠ å…¨å±€ç©ºé—´ä¿¡æ¯ï¼Œæ¯ä¸€ä¸ªäºŒç»´ç‰¹å¾å›¾å˜ä¸ºä¸€ä¸ªå®æ•°ã€‚è¡¨ç¤ºç‰¹å¾é€šé“ä¸Šå…¨å±€åˆ†å¸ƒï¼ŒåŠ ä¸ŠSæ¨¡å—ä½¿å¾—é è¿‘è¾“å…¥çš„å±‚ä¹Ÿå¯ä»¥è·å¾—å…¨å±€æ„Ÿå—é‡<br>Excitation: like gate in RNN. æ¯ä¸ªé€šé“ç”Ÿæˆæƒé‡ï¼Œå»ºæ¨¡ç›¸å…³æ€§ï¼Œcapture channel-wise dependencies<br>Wçš„è¦æ±‚ <em> learn non-linear interaction </em> learn a non-mutually-exclusive relationship since we would like to ensure that multiple channels are allowed to be emphasised opposed to one-hot activation<br>Reweight: multiply with feature map  </p>
<p>åµŒå…¥Inceptionï¼š<br>åµŒå…¥ResNetï¼š additionä¹‹å‰è¿›è¡Œscaleæ“ä½œï¼Œé˜²æ¢¯åº¦å¼¥æ•£</p>
<hr>
<h2 id="hard-negative-mining-in-ssd-focal-loss">Hard Negative Mining in SSD &amp; Focal Loss</h2>
<ol>
<li><p>Hard Negative Mining in SSD ä½œä¸ºä¸­é—´ç»“æœå¤„ç†çš„æ­¥éª¤ã€‚åªæœ‰GTæ¡†/å’ŒGTæ¡†IoUå¤§äºé˜ˆå€¼çš„æ‰æ˜¯æ­£æ ·æœ¬ï¼ˆå³æ­£ç¡®æ£€æµ‹æ¡†ï¼Œæ•°é‡å°‘ï¼‰ï¼Œå…¶ä»–éƒ½æ˜¯è´Ÿæ ·æœ¬ï¼ˆå³é”™è¯¯çš„æ£€æµ‹æ¡†ï¼Œæ•°é‡å¤§ï¼‰</p>
<blockquote>
<p><u><strong>ä¸ºäº†æ­£è´Ÿæ ·æœ¬æ•°é‡å¹³è¡¡</strong></u>ï¼Œé˜²æ­¢å°‘é‡å…³é”®çš„ï¼ˆæå‡æ€§èƒ½ï¼‰çš„è´Ÿæ ·æœ¬è¢«å¤§é‡æ­£æ ·æœ¬æ©ç›–è€Œæ— æ³•è¢«å­¦ä¹ /ä¼˜åŒ–åˆ°ã€‚<br>è§£å†³é”™è¯¯æ ·ä¾‹å¤ªå¤šï¼Œ<u><strong>æ­£ç¡®æ ·ä¾‹å¤ªå°‘</strong></u>ï¼Œæ©ç›–æ­£ç¡®æ ·ä¾‹çš„é—®é¢˜ã€‚  </p>
</blockquote>
<p> <strong>Hard Negative Mining in SSD</strong>: ç›´æ¥é€šè¿‡æ ¹æ®ç½®ä¿¡åº¦æŸå¤±ï¼Œ<u><strong>æ’åºç­›é€‰</strong></u> æ¥é€‰æ‹©åˆ†ç±»æŸå¤±æœ€å¤§çš„è´Ÿæ ·æœ¬ï¼ˆå³ä¸æ˜¯ç‰©ä½“ä½†æ˜¯æœ‰æœ€é«˜çš„åˆ†ç±»ç½®ä¿¡åº¦ -&gt; å›°éš¾åˆ†ç±»æ ·æœ¬<em>è¿·æƒ‘æ€§ï¼Œä¸¢å¼ƒä¸æ˜¯ç‰©ä½“ä½†åˆ†ç±»ç½®ä¿¡åº¦ç›¸å¯¹è¾ƒä½ -&gt; ç®€å•</em>é”™è¯¯ä¸ä¸¥é‡/ä¸æ˜æ˜¾ï¼‰ï¼Œåªä¿ç•™åˆ†ç±»ç½®ä¿¡åº¦æŸå¤±è¾ƒå¤§çš„ï¼Œäººä¸ºä¿è¯æ ·æœ¬æ•°é‡å¹³è¡¡ã€‚</p>
</li>
<li><p>Focal Loss ç”¨äºæŸå¤±å‡½æ•°ä¸­</p>
<blockquote>
<p><u><strong>ä¸ºäº†èƒ½å­¦åˆ°å›°éš¾æ ·ä¾‹</strong></u>ï¼Œå­¦åˆ°æ›´å¤šï¼Œä¸è¢«ç®€å•æ©ç›–ã€‚<br>è§£å†³é”™è¯¯æ ·ä¾‹ä¸­ï¼Œ<u><strong>ç®€å•çš„é”™è¯¯æ ·ä¾‹å¤ªå¤š</strong></u>ï¼Œå›°éš¾é”™è¯¯æ ·ä¾‹å¤ªå°‘ï¼Œä¸”æ±‚å’Œåæ©ç›–å›°éš¾çš„é”™è¯¯æ ·ä¾‹ï¼Œè€Œå¯¼è‡´æ£€æµ‹å™¨å­¦ä¸åˆ°å›°éš¾çš„é”™è¯¯æ ·ä¾‹ï¼ˆçœŸæ­£éœ€è¦å­¦/ä¼˜åŒ–çš„ï¼‰ã€‚  </p>
</blockquote>
<p> <strong>Focal Loss</strong>: é€šè¿‡ç»™ä¸åŒç½®ä¿¡åº¦çš„æ ·æœ¬<u><strong>å¢åŠ æƒé‡</strong></u>çš„æ–¹æ³•ã€‚æ¥è¿‘0/1ä¸ºç®€å•æ ·æœ¬ï¼Œæ¥è¿‘0.5ä¸ºéš¾æ ·æœ¬ã€‚æ‰€ä»¥æ­£ä¾‹x (1-p)ï¼Œè´Ÿä¾‹x pï¼Œä½¿ç”¨ <em>ä¸ç¡®å®šç¨‹åº¦</em> ä½œä¸ºæƒé‡ã€‚éš¾æ˜“çš„é”™è¯¯éƒ½ä¼šå­¦ï¼Œä½†å›°éš¾çš„é”™è¯¯å¯¹losså½±å“æ›´å¤§ã€‚<br> <img src="https://latex.codecogs.com/svg.latex?L%28p,y%29=-%28y\cdots%20%281-p%29\cdots%20\log%28p%29+%281-y%29\cdots%20p\cdots\log%281-p%29%29" alt="latex_equ"></p>
</li>
</ol>
<hr>
<h2 id="one-stage-two-stage-detector">One-stage &amp; Two-stage detector</h2>
<h4 id="rcnn">RCNN</h4>
<p><img src="Figures/6F235DE5-4774-4527-9FC9-F8EAF8252AEE.png" alt=""></p>
<h2 id="iccv-2019-workshop">ICCV 2019 workshop</h2>
<h4 id="lpirc">LPIRC</h4>
<p><a href="https://rebootingcomputing.ieee.org/lpirc/2019">https://rebootingcomputing.ieee.org/lpirc/2019</a><br>Winner talk:  <a href="http://ieeetv.ieee.org/conference-highlights/award-winning-methods-for-lpirc-tao-sheng-lpirc-2018?rf=series%7C3">http://ieeetv.ieee.org/conference-highlights/award-winning-methods-for-lpirc-tao-sheng-lpirc-2018?rf=series|3</a><br> <a href="http://ieeetv.ieee.org/conference-highlights/deeper-neural-networks-kurt-keutzer-lpirc-2018?rf=series%7C3">http://ieeetv.ieee.org/conference-highlights/deeper-neural-networks-kurt-keutzer-lpirc-2018?rf=series|3</a><br><em>Real Time Object Detection On Low Power Embedded Platforms</em><br><em>1810.01732.pdf</em></p>
<h4 id="compact-and-efficient-feature-representation-and-learning">Compact and Efficient Feature Representation and Learning</h4>
<p><a href="http://www.ee.oulu.fi/~lili/CEFRLatICCV2019.html">http://www.ee.oulu.fi/~lili/CEFRLatICCV2019.html</a><br>DCNN network quantization and compression, energy efficient network architectures, binary hashing techniques and data efficient techniques like meta learning</p>
<hr>
<h2 id="triplet-loss">Triplet Loss</h2>
<p><img src="Figures/20150707120209693.png" alt=""><br>ä¸‰å…ƒç»„: [anchor, positive, negative] æ‹‰è¿‘posï¼Œæ¨è¿œneg</p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathcal{L}_{\mathrm{tri}}%28\theta%29=\sum_{a,%20p,%20n%20\atop%20y_{a}=y_{p}%20\neq%20y_{n}}\left[m+D_{a,%20p}-D_{a,%20n}\right]_{+}" alt="latex_equ"></p>
<blockquote>
<p>é€‰å‡ºBä¸ªtripletsï¼Œåªç”¨äº†Bä¸ªè®­ç»ƒï¼Œå®é™…ä¸Šå¯ä»¥æœ‰<code>6B^2-4B</code>ç§tripletsçš„ç»„åˆï¼ˆ<em>Bä¸ªanchorï¼Œposå›ºå®šä¸€å¯¹ä¸€ï¼Œé™¤æ­¤äºŒå…¶ä»–æ‰€æœ‰éƒ½å¯ä»¥ä¸ºnegï¼Œ3B-2ç§ï¼›anchorå’Œposäº¤æ¢ä¹˜2</em>ï¼‰ <code>2*B*(3B-2)</code>ç§  </p>
</blockquote>
<p>éš¾è®­ç»ƒï¼Œéœ€è¦<strong>triplet mining</strong>ã€‚åˆ†å‡ºhardï¼Œsemi-hardï¼Œeasyä¸‰ç§æ ·æœ¬<br><img src="Figures/02_triplets.png" alt=""></p>
<ol>
<li><p><u><strong>Batch-Hard</strong></u><br><u>é€‰æ‹©Pä¸ªç±»åˆ«ï¼ˆäººï¼‰ï¼Œæ¯ä¸ªç±»åˆ«Kä¸ªæ ·æœ¬ï¼ˆç…§ç‰‡ï¼‰ï¼ŒPKä¸ªæ ·æœ¬ä½œä¸ºanchor</u> ã€‚æ¯ä¸ªanchoråªé€‰æ‹©<strong>è·ç¦»æœ€è¿œçš„poså’Œè·ç¦»æœ€è¿‘çš„neg</strong>ï¼ˆæœ€hardï¼‰</p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathcal{L}_{\mathrm{BH}}%28\theta%20;%20X%29=\overbrace{\sum_{i=1}^{P}%20\sum_{a=1}^{K}}^{\text%20{all%20anchors}}%20\left[m%20+%20%20\overbrace{\max_{p=1%20\ldots%20K}%20D\left%28%20f_{\theta}\left%28x_{a}^{i}\right%29,%20f_{\theta}%28x_p^i%29\right%29}^{\text%20{hardest%20positive}}%20-%20\underbrace{\min\limits_{j=1%20\ldots%20P,\;%20n=1\ldots%20K%20\atop%20j%20\neq%20i}%20D\left%28f_{\theta}\left%28x_{a}^{i}\right%29,%20f_{\theta}\left%28x_{n}^{j}\right%29\right%29}_{\text%20{hardest%20negative}}\right]_{+}%20" alt="latex_equ"><br>ä¸€å…±<img src="https://latex.codecogs.com/svg.latex?P_K" alt="latex_equ">ä¸ªtriplets</p>
</li>
<li><p><u><strong>Batch-All</strong></u><br>é€‰æ‹©Pä¸ªç±»åˆ«ï¼ˆäººï¼‰ï¼Œæ¯ä¸ªç±»åˆ«Kä¸ªæ ·æœ¬ï¼ˆç…§ç‰‡ï¼‰ï¼ŒPKä¸ªæ ·æœ¬ä½œä¸ºanchorï¼Œlossè®¡ç®—æ‰€æœ‰çš„poså’Œæ‰€æœ‰çš„negï¼ˆå’Œbaselineé€‰æ³•ç›¸åŒï¼‰</p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathcal{L}_{\mathrm{BA}}%28\theta%20;%20X%29=%20\overbrace{\sum_{i=1}^{P}%20\sum_{a=1}^{K}}^{\text%20{all%20anchors}}%20\overbrace{\sum_{p=1%20\atop%20p%20\neq%20a}^{K}}^{\text{all%20pos.}}%20\overbrace{\sum_{j=1%20\atop%20j%20\neq%20i}^{P}%20\sum_{n=1}^{K}}^{\text%20{all%20neg.}}\left[m+d_{j,%20a,%20n}^{i,%20a,%20p}\right]_{+}" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?d_{j,%20a,%20n}^{i,%20a,%20p}=D\left%28f_{\theta}\left%28x_{a}^{i}\right%29,%20f_{\theta}\left%28x_{p}^{i}\right%29\right%29-D\left%28f_{\theta}\left%28x_{a}^{i}\right%29,%20f_{\theta}\left%28x_{n}^{j}\right%29\right%29" alt="latex_equ"><br><img src="https://latex.codecogs.com/svg.latex?P_K" alt="latex_equ">ä¸ªanchorï¼Œæ¯ä¸ªæœ‰<img src="https://latex.codecogs.com/svg.latex?K-1" alt="latex_equ">çš„posï¼Œ<img src="https://latex.codecogs.com/svg.latex?P_K-K" alt="latex_equ">ä¸ªnegï¼ˆå…¶ä»–æ‰€æœ‰ç±»åˆ«çš„æ ·æœ¬ï¼‰ã€‚ä¸€å…±<img src="https://latex.codecogs.com/svg.latex?P_K%28K-1%29%28P_K-K%29" alt="latex_equ">ä¸ªtriplets</p>
</li>
</ol>
<hr>
<h2 id="long-short-term-memory-lstm-">Long Short Term Memory (LSTM)</h2>
<blockquote>
<p>Handling long-term dependencies</p>
</blockquote>
<p>LSTM blocksğŸ‘‡</p>
<p><img src="Figures/image-20191018172300763.png" alt="image-20191018172300763"></p>
<h4 id="core-idea">Core idea</h4>
<p><img src="Figures/image-20191018172422527.png" alt="image-20191018172422527"></p>
<p>ğŸ‘†<strong>Cell state</strong> convey information straight down along the entire chain</p>
<p><img src="https://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-gate.png" alt="img"></p>
<p>ğŸ‘†<strong>Gate</strong> controls whether add/remove information to the cell state</p>
<hr>
<p><img src="Figures/image-20191018174346388.png" alt="image-20191018174346388"></p>
<p>ğŸ‘†<strong>Forget Gate</strong>: how many last state information(<img src="https://latex.codecogs.com/svg.latex?c_{t-1}" alt="latex_equ">) keep/forget.</p>
<p><img src="Figures/image-20191018174812836.png" alt="image-20191018174812836"></p>
<p>ğŸ‘†<strong>Input Gate</strong>: what new information weâ€™re going to store in the cell state.</p>
<p>Two parts: <strong>sigmoid</strong> layer decide which part of values we will update, <strong>tanh</strong> layer create a vector of new candidate values <img src="https://latex.codecogs.com/svg.latex?\tilde{C}_t" alt="latex_equ"></p>
<p><img src="Figures/image-20191018175359262.png" alt="image-20191018175359262"></p>
<p>ğŸ‘†Apply to cell state: forget first, then partially add new candidate</p>
<p><img src="Figures/image-20191018175611169.png" alt="image-20191018175611169"></p>
<p>ğŸ‘†<strong>Output Gate</strong>: decide what weâ€™re going to output</p>
<p>Two parts: <strong>sigmoid</strong> layer decide which parts of the cell state going to output, <strong>tanh</strong> layer filters cell state. <strong>Multiply</strong> them together to get final output.</p>
<hr>
<h4 id="variants">Variants</h4>
<p><strong>1. Peephole Connection</strong></p>
<p>gate layer look at the cell state</p>
<p><img src="Figures/image-20191018192328653.png" alt="image-20191018192328653"></p>
<p><strong>2. Input&amp;Forget Together</strong></p>
<p>make what to forget and what to add together. Only forget when going to input something, only input when we forget.</p>
<p><img src="Figures/image-20191018192633284.png" alt="image-20191018192633284"></p>
<p><strong>3. Gated Recurrent Unit</strong></p>
<p>Combines the forget and input gated into &quot;update gate&quot;. Merge the cell state and the hidden state.</p>
<p><img src="Figures/image-20191018192913785.png" alt="image-20191018192913785"></p>
<p><a href="https://colah.github.io/posts/2015-08-Understanding-LSTMs/">Reference</a></p>
<hr>
<h2 id="nasnet">NASNet</h2>
<blockquote>
<p>å…ˆåœ¨å°æ•°æ®é›†ä¸­è®­ç»ƒç½‘ç»œå•å…ƒï¼Œå†åœ¨å¤§æ•°æ®é›†ä¸­å †å å•å…ƒ  </p>
</blockquote>
<p>å­¦ä¹ ç½‘ç»œä¸­å †å çš„ç½‘ç»œå•å…ƒ1. Normal cellå°ºå¯¸ä¸å˜ 2. Reduction cellå‡å°ºå¯¸<br>æ§åˆ¶å™¨ï¼šä¸€ç›´åœ¨æ‰§è¡Œä¸¤ä¸ªç‰¹å¾å›¾çš„<u><strong>èåˆ</strong></u><br><img src="Figures/v2-88f671125c2996924eb8a2c5b48c965d_r.jpg" alt=""><br>é€‰æ‹©ç¬¬ä¸€ä¸ªfeature mapå’Œç¬¬äºŒä¸ªfeature map(ç°è‰²) <code>2</code> ï¼Œè®¡ç®—è¾“å…¥çš„feature map A B(é»„è‰²) <code>2</code> ï¼Œé€‰æ‹©æ“ä½œèåˆä¸¤ä¸ªfeature map(ç»¿è‰²) <code>1</code><br>RNNé¢„æµ‹ï¼Œè¾“å‡º<code>2 x 5 x B</code>å…¶ä¸­ <em>normal cell</em> + <em>reduction cell</em> ï¼›æ¯ä¸ªéƒ½æœ‰Bä¸ªå—å †å ï¼›æ¯ä¸ªblockæœ‰äº”ä¸ªè¾“å‡ºğŸ‘†<br>NASNetè¿ç§»å­¦ä¹ ä¼˜åŒ–ç­–ç•¥ä¸ºProximal Policy Optimization(PPO) ğŸ‘ˆ<br>æå‡º<strong>scheduled drop path</strong>ï¼Œéšæœºä¸¢å¼ƒéƒ¨åˆ†åˆ†æ”¯ï¼Œå¢åŠ ç½‘ç»œå†—ä½™overfittingï¼Œç±»ä¼¼ã€ŒInceptionã€<br>ä¸¢å¼ƒæ¦‚ç‡éšæ—¶é—´çº¿å‹å¢åŠ ï¼Œè®­ç»ƒæ¬¡æ•°å¤šå®¹æ˜“è¿‡æ‹Ÿåˆ</p>
<hr>
<h2 id="detnas">DetNAS</h2>
<p><strong>weight sharing</strong> inherit its weights from supernet instead of training from scratch<br><strong>joint optimization</strong> weight and architecture<br><strong>No proxy task or dataset</strong> ä¸éœ€è¦æå‰è®­ç»ƒå°ç½‘ç»œ/å°æ¨¡å—ï¼Œä¹Ÿä¸éœ€è¦ä»å°æ•°æ®é›†åˆ°å¤§æ•°æ®é›†è®­ç»ƒ<br><strong>train from scratch</strong> æ›´å¤šè¿­ä»£ï¼Œä¸é€‚ç”¨äºå°æ•°æ®é›†<br>é¦–å…ˆè®­ç»ƒ(pretrain+finetune)ä¸€ä¸ªsupernetï¼Œç„¶åå†supernetç©ºé—´ä¸­æ‰¾ï¼›ç›´æ¥åœ¨detä»»åŠ¡<code>Vdet</code>ä¸Šæœç´¢ <u>proxyless</u> ğŸ‘‡<br><img src="Figures/DEEE8DD1-BD56-46A9-BA8A-6D16942C8049.png" alt=""><br>ä¼˜ç‚¹ï¼š</p>
<ol>
<li><p>Decoupling: æ²¡æœ‰weightå’Œarchitectureä¹‹é—´çš„bias interaction</p>
</li>
<li><p><u>supernetè®­å¥½åï¼Œç›´æ¥ç”¨valåœ¨supernetä¸Šæœç´¢</u> ç‰¹å®šåº”ç”¨åœºæ™¯çš„ç»“æ„ï¼Œè€Œä¸æ˜¯finetune</p>
</li>
</ol>
<h4 id="-supernet-">è®­ç»ƒsupernetğŸ‘‡</h4>
<p><img src="Figures/78DB7B34-1276-4AE0-AC78-0C38A7308692.png" alt=""></p>
<ol>
<li><p>Single path sampling: ä½¿è®­ç»ƒå’Œæµ‹è¯•çš„é…ç½®ä¸€è‡´<br><img src="Figures/74B60042-F0B7-48C0-BC3E-47E80BE0E4B0.png" alt=""></p>
</li>
<li><p>åŒæ­¥BN: <u>BN can not be frozen</u>, ä¸åŒpath BNçš„å‚æ•°ä¸åŒï¼ˆGroupNormé€Ÿåº¦æ…¢ï¼‰</p>
</li>
</ol>
<h4 id="-">æœç´¢å­ç½‘ç»“æ„</h4>
<p>éå†æ¯ä¸ªpathï¼Œéœ€è¦é‡æ–°åœ¨trainsetä¸Šæœé›†è®¡ç®—BNçš„meanå’Œvar<br>ä¸ç”¨trainsetè®­ç»ƒå­ç½‘ï¼Œè€Œç›´æ¥åœ¨valsetä¸Ševal</p>
<h4 id="target-task-dataset-finetune-">Target task datasetä¸Šfinetuneå­ç½‘ç»“æ„</h4>
<hr>
<h2 id="self-supervised-sample-mining">Self-supervised Sample Mining</h2>
<blockquote>
<p><u><strong>semi-supervised</strong></u> <u><strong>weakly-supervised</strong></u> ä½¿ç”¨æœªæ ‡æ³¨çš„æ•°æ®æå‡æ¨¡å‹æ€§èƒ½   </p>
</blockquote>
<p><img src="Figures/image.png" alt=""><br>è¿™ä¸ªæ¡†æ¶æœ‰ä¸¤ä¸ªé˜¶æ®µï¼Œåˆ†åˆ«æ˜¯é€šè¿‡SSMå¯¹é«˜ä¸€è‡´æ€§æ ·æœ¬è¿›è¡Œä¼ªæ ‡æ³¨é˜¶æ®µå’Œé€šè¿‡ALé€‰æ‹©ä½ä¸€è‡´æ€§æ ·æœ¬é˜¶æ®µã€‚é¦–å…ˆä½¿ç”¨å·²æ ‡æ³¨çš„å›¾ç‰‡å¯¹æ¨¡å‹è¿›è¡Œfine-tuneï¼Œå¯¹æœªæ ‡æ³¨æˆ–éƒ¨åˆ†æ ‡æ³¨çš„å›¾ç‰‡æå–region proposalsï¼ˆæœªæ ‡æ³¨æ ·æœ¬ï¼‰ï¼ŒæŠŠè¿™äº› <strong>region proposals <u>ç²˜è´´</u> åˆ°å·²æ ‡æ³¨çš„å›¾ç‰‡ä¸­è¿›è¡Œäº¤å‰å›¾ç‰‡éªŒè¯ï¼Œæ ¹æ®é‡æ–°é¢„æµ‹å‡ºæ¥çš„ç½®ä¿¡åº¦ç¡®å®šå¦‚ä½•å¯¹æœªæ ‡æ³¨æ ·æœ¬è¿›è¡Œæ ‡æ³¨</strong> ã€‚å¯¹äºé«˜ä¸€è‡´æ€§æ ·æœ¬ï¼Œç›´æ¥è¿›è¡Œä¼ªæ ‡æ³¨ï¼Œå¯¹äºä½ä¸€è‡´æ€§æ ·æœ¬ï¼Œé€šè¿‡ALæŒ‘é€‰å‡ºæ¥ï¼Œè®©ç›¸å…³äººå‘˜è¿›è¡Œæ ‡æ³¨ã€‚ä¼ªæ ‡æ³¨çš„æ ·æœ¬ç”¨äºæ¨¡å‹çš„fine-tuneï¼Œè€Œæ–°æ ‡æ³¨çš„æ ·æœ¬æ·»åŠ åˆ°å·²æ ‡æ³¨çš„å›¾ç‰‡ä¸­ï¼ŒåŒæ—¶ä¹Ÿç”¨äºæ¨¡å‹çš„fine-tune<br>å¯¹äºå¥½çš„æ ·æœ¬<code>xi</code>ï¼Œproposalä¸­çš„å†…å®¹å¯ä»¥å¾ˆå¥½çš„å±•ç¤ºjç±»çš„ç‰¹å¾ï¼Œç²˜è´´åˆ°æ²¡æœ‰jç±»çš„å›¾ç‰‡ä¸­ï¼Œæ–°ç”Ÿæˆçš„å›¾ç‰‡ä¸­çš„proposalæœ‰åŒ…å«<code>xi</code>çš„proposalï¼Œä¸”å…·æœ‰å¾ˆå¤§çš„æ¦‚ç‡å€¼ï¼Œ<u><strong>é«˜ä¸€è‡´æ€§</strong></u>è®¤ä¸ºä¹‹å‰çš„æ ·æœ¬æ¡†å‡†ç¡®æ— é”™è¯¯â¡ï¸æ­£æ ·æœ¬<br>ä»»åŠ¡åˆ†ç±»ğŸ‘‡<br><img src="Figures/image%202.png" alt=""></p>
<hr>
<h2 id="bi-box-regression-for-pedestrian-detection-and-occlusion-estimation">Bi-box Regression for Pedestrian Detection and Occlusion Estimation</h2>
<blockquote>
<p>Part detectorï¼Œé’ˆå¯¹è¡Œäººé®æŒ¡é—®é¢˜ï¼Œå›å½’ã€Œå…¨èº«ã€+ã€Œå¯è§ã€ä¸¤ä¸ªæ¡†  </p>
</blockquote>
<p><img src="Figures/97B54C4E-F68D-4AB8-B030-A7C87315CE3E.png" alt=""><br>äºŒåˆ†æ”¯ç½‘ç»œï¼š</p>
<ol>
<li><strong>Full body estimation</strong> åªå¯¹pos proposalå›å½’</li>
<li><strong>Visible part estimation</strong> å¯¹poså’Œnegçš„proposalå›å½’ï¼ˆFG&amp;BGï¼‰ï¼Œ <u>neg proposalå›å½’ç¼©å°åŒºåŸŸ <img src="https://latex.codecogs.com/svg.latex?\to" alt="latex_equ"> 0</u><br>pos/neg proposalæ ¹æ®å’Œæ ‡æ³¨(full-body)çš„IoUå†³å®š<br><img src="Figures/AFA72E30-3E28-4167-8CC3-28C74B49AA10.png" alt=""><br>ğŸ‘†proposalç”±RPNè·å¾—ï¼Œsoftmax1å’Œsoftmax2é¢„æµ‹è¡Œäººå¾—åˆ†ã€‚ <u>fuse</u> æ—¶ï¼Œä¸¤ä¸ªéƒ½ä¸ºposï¼Œè¾“å‡ºpæ›´é«˜ï¼›ä¸€ä¸ªä¸ºnegï¼Œå¦ä¸€åˆ†æ”¯posï¼Œåˆ™posåˆ†æ”¯å¢åŠ p</li>
</ol>
<h4 id="training">Training</h4>
<p><u>æ ·æœ¬æ ‡æ³¨ä¸¤ä¸ªæ¡† (vis/full)</u>ã€‚æŠŠäº§ç”Ÿçš„proposal<code>P={x,y,w,h}</code>å’Œæ ‡æ³¨æ¡†<code>Q=(Full,Vis)</code>matchï¼Œpos-proposalè§„åˆ™ä¸º<code>IoU(P,F)&gt;thresh_1</code> &amp;&amp; <code>C(P,V)&gt;thresh_2</code>. Cå®šä¹‰ä¸ºğŸ‘‡<img src="https://latex.codecogs.com/svg.latex?C%28P,\bar{V}%29=\frac{\text%20{Area}%28P\cap\bar{V}%29}{\text%20{Area}%28\bar{V}%29}" alt="latex_equ"></p>
<p>è®­ç»ƒæ ·æœ¬<code>X=(Img, P, cate=1, F, V)</code>ï¼Œregression targetä¸ºğŸ‘‡<br><img src="https://latex.codecogs.com/svg.latex?\bar{f}^x=\frac{\bar{F}^x-P^x}{P^W},\;\bar{f}^y=\frac{\bar{F}^y-P^y}{P^h}" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?\bar{f}^w=\log%28\frac{\bar{F}^w}{P^w}%29,\;\bar{f}^h=\log%28\frac{\bar{F}^h}{P^h}%29" alt="latex_equ"></p>
<p>Neg-proposal=1.background   2.poorly aligned proposal   å›å½’w,h -&gt; 0</p>
<blockquote>
<p>Why should force <em>visible part of neg-proposal</em> shrink? ã€Œvisåˆ†æ”¯å¯¹poså’Œnegéƒ½å¤„ç†ã€ #æ²¡æ‡‚<br>If the visible part estimation branch is trained to only regress visible parts for positive pedestrian proposals, the training of this branch would be dominated by pedestrian examples which are non-occluded or slightly occluded. For these pedestrian proposals, their ground-truth visible part and full body regions overlap largely. As a result, the estimated visible part region of a negative pedestrian proposal is often close to its estimated full body re- gion and the difference between the two branches after training would not be as large as the case in which the visible part regions of negative examples are forced to shrink to their centers.  </p>
</blockquote>
<p>ä¸å¯¹è´Ÿæ ·æœ¬å¤„ç†ï¼Œåˆ™å¯¹è´Ÿæ ·æœ¬çš„é¢„æµ‹ç»“æœä¸¤ä¸ªåˆ†æ”¯ç›¸åŒã€Œfullåˆ†æ”¯å¯¹æ‰€æœ‰æ ·æœ¬å›å½’åˆ°GTï¼Œvisåˆ†æ”¯å¯¹æ­£æ ·æœ¬å›å½’åˆ°GTï¼Œå¯¹è´Ÿæ ·æœ¬å›å½’åˆ°0ã€<br><img src="Figures/D29D7BC4-9682-4E65-AB16-3A92A974DD47.png" alt=""><br>ğŸ‘†è“è‰²æ¡†ï¼Œå’Œfull(GT)é‡åˆåº¦é«˜ï¼Œä½†å’Œvisé‡åˆåº¦ä½ã€‚åœ¨Faster-RCNNä¸­è¢«è®¤ä¸ºposï¼Œåœ¨æœ¬æ–‡ä¸­è®¤ä¸ºnegã€‚æ›´å¼ºçš„è¯„ä»·æ ‡å‡†</p>
<hr>
<h2 id="precision-gating-improving-neural-network-efficiency-with-dynamic-dual-precision-activations">Precision Gating: Improving Neural Network Efficiency with Dynamic Dual-Precision Activations</h2>
<p><u><strong>ç½‘ç»œé‡åŒ–</strong></u><br>Network compression: sparsity, quantization, and binarization<br>ä½¿ç”¨ä½ç²¾åº¦çš„æµ®ç‚¹è¿ç®—ï¼Œç›¸æ¯”äºé™æ€ç¡®å®šæ¯ä¸ªweightå’Œactivationçš„ç²¾åº¦ï¼Œæœ¬æ–‡<strong>æ ¹æ®ç½‘ç»œè¾“å…¥</strong>(ä¾‹å¦‚èƒŒæ™¯ä¸éœ€è¦ç²¾ç¡®è®¡ç®—)åŠ¨æ€ç¡®å®š <strong>Tuning the bit width per layer</strong></p>
<h4 id="precision-gating">Precision Gating</h4>
<blockquote>
<p>Computes most features with low-precision arithmetic ops and only updates few important features to a high-precision  </p>
</blockquote>
<ol>
<li>å¯¹äºæ‰€æœ‰å±‚ä½ç²¾åº¦è®¡ç®—</li>
<li>å¯¹äºè¾“å‡ºçš„feature mapä¸­è¾ƒå¤§å€¼è®¤ä¸ºé‡è¦ç‰¹å¾ï¼Œå¯¹å…¶è¿›è¡Œç¨€ç–æ›´æ–°ï¼Œæé«˜ç²¾åº¦(sparse back propagation)</li>
</ol>
<p>ç”¨åœ¨shufflenet v2ä¸Šæå‡26% ImageNetåˆ†ç±»ç²¾åº¦</p>
<hr>
<h2 id="repulsion-loss-detecting-pedestrians-in-a-crowd">Repulsion Loss: Detecting Pedestrians in a crowd</h2>
<blockquote>
<p>ReIdçš„occludeé—®é¢˜ï¼Œä½¿ä¸åŒç›®æ ‡çš„æ£€æµ‹æ¡†è¿œç¦»ã€Œç±»ä¼¼triplet lossã€  </p>
</blockquote>
<p><img src="Figures/%E6%88%AA%E5%B1%8F2020-02-23%E4%B8%8A%E5%8D%8812.28.04.png" alt=""></p>
<p><img src="https://latex.codecogs.com/svg.latex?L=L_{Attr}+\alpha*L_{RepGT}+\beta*L_{RepBox}" alt="latex_equ"></p>
<h4 id="attraction-term">Attraction term</h4>
<p>é‡‡ç”¨æ£€æµ‹æ¡†æ¶ä¸­bboxå›å½’loss</p>
<p><img src="https://latex.codecogs.com/svg.latex?L_{\mathrm{Attr}}=\frac{\sum_{P%20\in%20\mathcal{P}_{+}}%20\operatorname{Smooth}_{L%201}\left%28P,%20G_{A%20t%20t%20r}^{P}\right%29}{\left|\mathcal{P}_{+}\right|}" alt="latex_equ"></p>
<h4 id="repulsion-term-repgt-">Repulsion Term (RepGT)</h4>
<p>å’Œå‘¨å›´GTç›®æ ‡æ¡†è¿œç¦»ï¼Œè¿œç¦»IoUå¤§ä¸”æ²¡æœ‰åŒ¹é…çš„ç›®æ ‡æ¡†<br>å³<img src="https://latex.codecogs.com/svg.latex?G_{R%20e%20p}^{P}=\underset{G%20\in%20\mathcal{G}%20\backslash\left\{G_{A%20t%20r}^{P}\right\}}{\arg%20\max%20}%20\operatorname{IoU}%28G,%20P%29" alt="latex_equ"></p>
<p>ç±»ä¼¼IoU lossï¼ˆä¸æ˜¯IoUè€Œæ˜¯IoGï¼šè‹¥æœ€å°åŒ–IoUï¼Œåˆ™é¢„æµ‹æ¡†è¶Šå¤§IoUè¶Šå°ï¼‰</p>
<p><img src="https://latex.codecogs.com/svg.latex?\operatorname{IoG}%28P,G%29%20\overset{\triangle}{=}\frac{area%28P\cap%20G%29}{area%28G%29}" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?L_{\mathrm{RepGT}}=\frac{\sum_{P%20\in%20\mathcal{P}_{+}}%20\operatorname{Smooth}_{ln}\left%28\operatorname{IoG}%28P,%20G_{Rep}^{P}%29\right%29}{\left|\mathcal{P}_{+}\right|}" alt="latex_equ"></p>
<p>where</p>
<p><img src="https://latex.codecogs.com/svg.latex?\operatorname{smooth}_{l%20n}=\left\{\begin{array}{ll}%20{-\ln%20%281-x%29}%20&amp;%20{x%20\leq%20\sigma}%20\\%20{\frac{x-\sigma}{1-\sigma}-\ln%20%281-\sigma%29}%20&amp;%20{x&gt;\sigma}%20\end{array}\right." alt="latex_equ"><br>ä½¿é¢„æµ‹æ¡†é›†ä¸­åœ¨åŒ¹é…çš„ç›®æ ‡é™„è¿‘ï¼Œè€Œä¸ä¼šåç§»åˆ°ä¸´è¿‘ç‰©ä½“</p>
<h4 id="repulsion-term-repbox-">Repulsion Term (RepBox)</h4>
<p>é¢„æµ‹æ¡†å’Œå…¶ä»–é¢„æµ‹æ¡†è¿œç¦»ï¼ˆåŒ¹é…ä¸Šä¸åŒç‰©ä½“çš„ç›®æ ‡æ¡†ï¼‰<br><img src="https://latex.codecogs.com/svg.latex?L_{\mathrm{RepBox}}=\frac{\sum_{i%20\neq%20j}%20\operatorname{Smooth}_{l%20n}\left%28\operatorname{IoU}\left%28B^{P_{i}},%20B^{P_{j}}\right%29\right%29}{\sum_{i%20\neq%20j}%20\mathbb{1}\left[\operatorname{IoU}\left%28B^{P_{i}},%20B^{P_{j}}\right%29&gt;0\right]+\epsilon}" alt="latex_equ"></p>
<p>é˜²æ­¢ä¸åŒç‰©ä½“çš„ä¸¤ä¸ªæ£€æµ‹æ¡†è¢«NMSè¿‡æ»¤æ‰</p>
<hr>
<h2 id="normalization">Normalization</h2>
<p><img src="Figures/2020-02-24-16-07-43-image.png" alt=""></p>
<p>è¾“å…¥<img src="https://latex.codecogs.com/svg.latex?X" alt="latex_equ">ï¼Œ è¾“å‡º<img src="https://latex.codecogs.com/svg.latex?Y" alt="latex_equ">ï¼Œå‚æ•°<img src="https://latex.codecogs.com/svg.latex?\gamma" alt="latex_equ">å’Œ<img src="https://latex.codecogs.com/svg.latex?\beta" alt="latex_equ"> (parameters, æ¯ä¸ªç‰¹å¾å›¾ä¸€å¯¹)</p>
<p><img src="https://latex.codecogs.com/svg.latex?y_i=\gamma\cdot\frac{x_i-\mu}{\sigma}+\beta" alt="latex_equ"></p>
<p>Where <img src="https://latex.codecogs.com/svg.latex?\mu=\frac{\sum_i^Nx_i}{N}" alt="latex_equ">, <img src="https://latex.codecogs.com/svg.latex?\sigma=\sqrt{\frac{\sum_I^N%28x_i-\mu%29^2}{N}+\epsilon}" alt="latex_equ"> å‡å€¼å’Œæ–¹å·® (batch statistics)</p>
<p>ç»Ÿè®¡ä¸åŒæ ·æœ¬åœ¨åŒä¸€ä¸ªchannelåŒä¸€ä½ç½®æ•°æ®çš„å‡å€¼æ–¹å·® (reduce at batch dim hwc)</p>
<p>åå‘ä¼ æ’­æ—¶ï¼Œç”±äºå‡å€¼å’Œæ–¹å·®æ˜¯è¾“å…¥çš„å‡½æ•°</p>
<p><img src="https://latex.codecogs.com/svg.latex?\frac{d_{\ell}}{d_{x_{i}}}=\frac{d_{\ell}}{d_{y_{i}}}%20\cdot%20\frac{\partial_{y_{i}}}{\partial_{x_{i}}}+\frac{d_{\ell}}{d_{\mu}}%20\cdot%20\frac{d_{\mu}}{d_{x_{i}}}+\frac{d_{\ell}}{d_{\sigma}}%20\cdot%20\frac{d_{\sigma}}{d_{x_{i}}}" alt="latex_equ"></p>
<p>where <img src="https://latex.codecogs.com/svg.latex?\frac{\partial_{y_{i}}}{\partial_{x_{i}}}=\frac{\gamma}{\sigma}" alt="latex_equ">, <img src="https://latex.codecogs.com/svg.latex?\frac{d_{\ell}}{d_{\mu}}=-\frac{\gamma}{\sigma}\sum_i^N\frac{d_{\ell}}{d_{y_{i}}}" alt="latex_equ">, <img src="https://latex.codecogs.com/svg.latex?\frac{d_{\sigma}}{d_{x_{i}}}=-\frac{1}{\sigma}%28\frac{x_i\mu}{N}%29" alt="latex_equ"></p>
<p><img src="Figures/bn1.png" alt="http://hangzh.com/blog/images/bn1.png"></p>
<p>Ref: <a href="https://kevinzakka.github.io/2016/09/14/batch_normalization/">https://kevinzakka.github.io/2016/09/14/batch_normalization/</a></p>
<p><a href="https://kiddie92.github.io/2019/03/06/å·ç§¯ç¥ç»ç½‘ç»œä¹‹Batch-Normalizationï¼ˆä¸€ï¼‰ï¼šHowï¼Ÿ/">https://kiddie92.github.io/2019/03/06/å·ç§¯ç¥ç»ç½‘ç»œä¹‹Batch-Normalizationï¼ˆä¸€ï¼‰ï¼šHowï¼Ÿ</a></p>
<p><a href="https://www.cnblogs.com/shine-lee/p/11989612.html#å·ç§¯å±‚å¦‚ä½•ä½¿ç”¨batchnormï¼Ÿ">https://www.cnblogs.com/shine-lee/p/11989612.html</a></p>
<h4 id="training">Training</h4>
<p>==Batch Norm==å¯¹ä¸€ä¸ªbatchä¸­æ‰€æœ‰æ ·æœ¬çš„åŒä¸€channelè®¡ç®—ç»Ÿè®¡é‡ï¼Œå—batch_sizeå½±å“</p>
<p>==Layer Norm==å¯¹å•ä¸ªæ ·æœ¬è®¡ç®—ç»Ÿè®¡é‡ï¼Œç”¨äºRNN</p>
<p>==Instance Norm==å•æ ·æœ¬å•é€šé“è®¡ç®—ï¼Œé£æ ¼è¿ç§»</p>
<p>==Group Norm==å¯¹é€šé“åˆ†ç»„ï¼Œè§£å†³BNä¾èµ–batch_sizeçš„é—®é¢˜</p>
<blockquote>
<p>åŒä¸€å±‚ç‰¹å¾é€šé“ä¹‹é—´å…³è”æ€§å¼ºï¼Œç‰¹å¾å…·æœ‰ç›¸åŒåˆ†å¸ƒï¼Œå¯ä»¥group</p>
</blockquote>
<p>Switchable Normalizationè®¡ç®—BNã€LNã€INä¸‰ç§çš„ç»Ÿè®¡é‡ï¼Œç„¶ååŠ æƒ<img src="https://latex.codecogs.com/svg.latex?w_k" alt="latex_equ">ä½œä¸ºSNçš„å‡å€¼<img src="https://latex.codecogs.com/svg.latex?\mu" alt="latex_equ">å’Œæ–¹å·®<img src="https://latex.codecogs.com/svg.latex?\sigma" alt="latex_equ">ã€Œè§£å†³batch_sizeå½±å“ï¼Œè‡ªé€‚åº”ä¸åŒä»»åŠ¡ã€</p>
<p>normğŸ‘‡</p>
<p><img src="https://latex.codecogs.com/svg.latex?\hat{h}_{n%20c%20i%20j}=\gamma%20\frac{h_{n%20c%20i%20j}-\Sigma_{k%20\in%20\Omega}%20w_{k}%20\mu_{k}}{\sqrt{\Sigma_{k%20\in%20\Omega}%20w_{k}^{\prime}%20\sigma_{k}^{2}+\epsilon}}+\beta" alt="latex_equ"></p>
<p>åŠ æƒæƒé‡å½’ä¸€åŒ–ğŸ‘‡</p>
<p><img src="https://latex.codecogs.com/svg.latex?w_k=\frac{e^{\lambda_k}}{\sum_{z\in\{\text%20{bn,ln,in}\}}e^{\lambda_z}}" alt="latex_equ"></p>
<p><img src="Figures/2020-02-24-16-22-39-image.png" alt=""></p>
<h4 id="testing">Testing</h4>
<p>LN, INæ­£å¸¸è®¡ç®—ï¼ŒBNé‡‡ç”¨<u>batch average</u>æ–¹å¼ï¼Œå…·ä½“è¿‡ç¨‹æ˜¯ï¼Œå†»ç»“æ‰€æœ‰çš„å‚æ•°ï¼Œä»è®­ç»ƒé›†ä¸­éšæœºæŠ½å–ä¸€å®šæ•°é‡çš„æ ·æœ¬ï¼Œè®¡ç®—SNçš„å‡å€¼å’Œæ–¹å·®ï¼Œç„¶åä½¿ç”¨ä»–ä»¬çš„å¹³å‡å€¼ä½œä¸ºBNçš„ç»Ÿè®¡å€¼</p>
<p>Ref: <a href="https://zhuanlan.zhihu.com/p/39296570">https://zhuanlan.zhihu.com/p/39296570</a></p>
<h3 id="sync-bn">Sync BN</h3>
<blockquote>
<p>å¤šå¡è®­ç»ƒæ—¶ï¼Œä¼ ç»ŸBNåªåœ¨å•GPUä¸Šå½’ä¸€åŒ–ï¼Œæ”¹æˆå¤šä¸ªGPUä¹‹é—´åŒæ­¥ä¿¡æ¯ï¼›æ€§èƒ½æ˜æ˜¾æå‡</p>
</blockquote>
<p>é€šè¿‡è®¡ç®—å‡å€¼å’Œæ–¹å·®çš„ä¸­é—´é‡<img src="https://latex.codecogs.com/svg.latex?\sum%20x" alt="latex_equ">å’Œ<img src="https://latex.codecogs.com/svg.latex?\sum%20x^2" alt="latex_equ">ï¼Œåªéœ€åŒæ­¥ä¸€æ¬¡</p>
<p>æ ¹æ®<img src="https://latex.codecogs.com/svg.latex?D[x]=E[x^2]-E[x]^2" alt="latex_equ"></p>
<p><strong>FP</strong> è®¡ç®—å‡å€¼å’Œæ–¹å·® <img src="https://latex.codecogs.com/svg.latex?\mu=\frac{\sum%20x}{N}" alt="latex_equ">, <img src="https://latex.codecogs.com/svg.latex?\sigma=\sqrt{\frac{\sum%20x^2}{N}-\mu^2+\epsilon}" alt="latex_equ"></p>
<p><strong>BP</strong> è®¡ç®—<img src="https://latex.codecogs.com/svg.latex?\frac{d_{\ell}}{d_{x_{i}}}" alt="latex_equ">, <img src="https://latex.codecogs.com/svg.latex?\frac{d_\ell}{d_{\sum_k%20x}}" alt="latex_equ">å’Œ<img src="https://latex.codecogs.com/svg.latex?\frac{d_\ell}{d_{\sum_k%20x^2}}" alt="latex_equ">ï¼Œéƒ½å¯ä»¥å•å¡ä¸Šè®¡ç®—ï¼ŒåªåŒæ­¥ä¸€æ¬¡</p>
<p><img src="Figures/bn3-20200319223355972.png" alt="http://hangzh.com/blog/images/bn3.png"></p>
<p>Ref: <a href="https://hangzhang.org/PyTorch-Encoding/notes/syncbn.html">https://hangzhang.org/PyTorch-Encoding/notes/syncbn.html</a></p>
<p><strong>Improvement</strong>: MABN(ç§»åŠ¨å¹³å‡+å‡å°‘ç»Ÿè®¡é‡+ä¸­å¿ƒåŒ–æƒé‡) <a href="https://link.zhihu.com/?target=https%3A//arxiv.org/abs/2001.06838">https://arxiv.org/abs/2001.06838</a></p>
<hr>
<h2 id="universal-rcnn-universal-object-detection-via-transferable-graph-r-cnn">Universal-RCNN: Universal Object Detection via Transferable Graph R-CNN</h2>
<blockquote>
<p>è§£å†³æ£€æµ‹åŸŸè¿ç§»ï¼Œä¸åŒåŸŸ<u><strong>ç±»åˆ«</strong></u>å…³ç³»æ¨ç†()reasoning)å’Œè¿ç§»(transfer)</p>
</blockquote>
<p><strong>Intra-Domain Reasoning</strong>: åŸŸå†…éƒ¨å›¾è¡¨ç¤ºä¸Šä¼ æ’­ï¼Œç±»åˆ«ä¹‹é—´ç›¸å…³æ€§</p>
<p><strong>Inter-Graph Transfer</strong>: åŸŸé—´è¿ç§»ï¼Œä¸åŒåŸŸç±»åˆ«ä¹‹é—´å±‚æ¬¡å…³ç³»</p>
<p><img src="Figures/2020-02-25-20-41-49-image.png" alt=""></p>
<h4 id="intra-domain-reasoning-module">Intra-Domain Reasoning Module</h4>
<ol>
<li><p>ä½¿ç”¨backboneè®¡ç®—proposal feature (global <strong>semantic pool</strong>)</p>
</li>
<li><p>æ„å»º<strong>åŒºåŸŸ</strong>å…³ç³»å›¾<img src="https://latex.codecogs.com/svg.latex?G_{T\to%20T}" alt="latex_equ">ï¼ŒèŠ‚ç‚¹è¡¨ç¤ºregion proposalï¼Œè¾¹è¡¨ç¤ºå…³ç³»ã€‚proposalä¹‹é—´å…³è”å…³ç³»(attribute similarities, interactions)</p>
</li>
<li><p>å­¦ä¹ è¾¹æƒé‡<img src="https://latex.codecogs.com/svg.latex?\mathbf{Z}\mathbf{Z}^T" alt="latex_equ">ï¼Œåªä¿ç•™é‡è¦proposalå…³ç³»çš„<strong>ç¨€ç–é‚»æ¥çŸ©é˜µ</strong></p>
</li>
<li><p>propsoal featureåœ¨GCNè®¡ç®—ï¼Œå’ŒåŸå§‹ç‰¹å¾concatï¼Œå¾—åˆ°æ–°çš„global semantic pool <img src="https://latex.codecogs.com/svg.latex?\mathbf{P_S}" alt="latex_equ"></p>
</li>
</ol>
<p>sharing common features between categories via connected edges such as similar attributes &amp; relations.</p>
<p>improve feature rep. by adding adaptive contexts from global semantic pool</p>
<h4 id="inter-domain-transfer-module">Inter-Domain Transfer Module</h4>
<blockquote>
<p>bridge the gap between domains</p>
</blockquote>
<p>æºåŸŸç”¨ä¸Šè¿°æ¨¡å—æ„å»º<img src="https://latex.codecogs.com/svg.latex?\mathbf{P_S}" alt="latex_equ">ï¼Œæ„å»º<img src="https://latex.codecogs.com/svg.latex?\mathbf{G_{S\to%20T}}" alt="latex_equ">ï¼ŒGCNè®¡ç®—ä»æºåŸŸåˆ°ç›®æ ‡åŸŸè¿ç§»ï¼ŒconcatæºåŸŸç‰¹å¾</p>
<p><img src="Figures/2020-02-25-22-03-19-image.png" alt=""></p>
<hr>
<h2 id="model-agnostic-structured-sparsification-with-learnable-channel-shuffle">Model-Agnostic Structured Sparsification with Learnable Channel Shuffle</h2>
<blockquote>
<p>åˆ’åˆ†groupï¼Œconv<img src="https://latex.codecogs.com/svg.latex?\to" alt="latex_equ">group convï¼Œåˆ†ç»„è¿›è¡Œé€šé“shuffle</p>
</blockquote>
<p>å¸¸è§ç½‘ç»œå‹ç¼©æ–¹å¼ </p>
<ol>
<li><p>é‡åŒ–æƒé‡weight quantization </p>
<p>ä½ç²¾åº¦è¡¨ç¤ºï¼Œæ˜“æ€§èƒ½ä¸‹é™</p>
</li>
<li><p>çŸ¥è¯†è’¸é¦knowledge distillation </p>
<p>æ˜“å—æ•™å¸ˆç½‘ç»œå½±å“</p>
</li>
<li><p>ç½‘ç»œå‰ªænetwork pruning</p>
<p>å»æ‰éƒ¨åˆ†unimportantç½‘ç»œå‚æ•° (eg. filter pruning algo.)</p>
</li>
</ol>
<p>å‚æ•°weight normæ¥åˆ¤æ–­æ˜¯å¦pruneã€ŒL1æ­£åˆ™åŒ–å¯å¢åŠ sparsityã€</p>
<p>ä½¿ç”¨GroupConvä½¿é€šé“é—´ç¨€ç–è¿æ¥</p>
<p>ä½¿ç”¨learning-basedé€šé“shuffleå¢å¼ºinter-group info flow</p>
<p><strong>æ­¥éª¤</strong>ï¼šä½¿ç”¨structured regularizationè®­ç»ƒå¤§æ¨¡å‹ <img src="https://latex.codecogs.com/svg.latex?\to" alt="latex_equ"> å°†éƒ¨åˆ†convè½¬ä¸ºgroup conv <img src="https://latex.codecogs.com/svg.latex?\to" alt="latex_equ"> finetuneæ¢å¤ç²¾åº¦</p>
<h4 id="connectivity-patterns">connectivity patterns</h4>
<p>å·ç§¯æ ¸æƒé‡å€¼<img src="https://latex.codecogs.com/svg.latex?W_{j,i}" alt="latex_equ">è®¤ä¸ºinput output channelä¹‹é—´å…³è”æ€§</p>
<p>å·ç§¯<strong>groupable</strong>ï¼šæƒé‡å¯ä»¥æ’åˆ—æˆ<strong>block diagonal</strong></p>
<p>ğŸ‘‡ä¸€èˆ¬convçš„weightsï¼ˆchannelä¹‹é—´å…³è”ç¨‹åº¦ï¼‰</p>
<p><img src="/Users/mk/Library/Application Support/typora-user-images/image-20200226235116107.png" alt="image-20200226235116107"></p>
<p>ğŸ‘‡groupable convï¼Œä¸€ä¸ªchannelåªå’ŒåŒç»„å†…å‡ ä¸ªchannelæœ‰é«˜å“åº”ï¼Œå³block diagonalï¼ˆğŸ‘‡æœ‰ä¸¤ä¸ªblockï¼Œcardinality=2ï¼Œæ¯ä¸ªblockä¸­çš„å¯¹è§’å—0æƒ©ç½šï¼Œblockä¸­å·¦ä¸‹å³ä¸Šå—0.5æƒ©ç½šï¼Œblockå—å¤–1æƒ©ç½šï¼Œè§ä¸‹ä¸‹å›¾ï¼‰</p>
<p><img src="/Users/mk/Library/Application Support/typora-user-images/image-20200226235221529.png" alt="image-20200226235221529"></p>
<p>å˜ä¸ºå­¦ä¹ ==åˆ’åˆ†channel==é—®é¢˜ï¼ŒæŸå¤±å‡½æ•°æƒ©ç½šå·¦ä¸‹å³ä¸Šæ²¡æœ‰è¢«zero-outçš„æƒé‡ï¼Œä½¿ç”¨coordinate descentè®¡ç®—ï¼ˆçº¿æ€§è§„åˆ’é—®é¢˜ï¼Œor optimal transportï¼‰</p>
<h4 id="structured-regularization">Structured regularization</h4>
<p><img src="/Users/mk/Library/Application Support/typora-user-images/image-20200227000502981.png" alt="image-20200227000502981"></p>
<p>channel shuffleè§£é‡ŠğŸ‘‡</p>
<p><img src="/Users/mk/Library/Application Support/typora-user-images/image-20200227002933679.png" alt="image-20200227002933679"></p>
<h2 id="cosine-learning-rate-decay">Cosine Learning rate decay</h2>
<ol>
<li>warm upï¼šè®­ç»ƒå¼€å§‹å°†lrä»0é€æ­¥å¢åŠ åˆ°åˆå§‹å€¼</li>
<li>decayï¼šä½¿ç”¨cosineå‡½æ•°</li>
</ol>
<p><img src="Figures/1*BJCssPOCn4u__NoAZs392w-20200228202856582.png" alt="img"></p>
<p>å¸¸è§ä¸ºstep devay</p>
<p><img src="Figures/stepdecay.png" alt="stepdecay"></p>
<p>Ref: <a href="https://medium.com/@scorrea92/cosine-learning-rate-decay-e8b50aa455b">https://medium.com/@scorrea92/cosine-learning-rate-decay-e8b50aa455b</a></p>
<h2 id="learning-when-and-where-to-zoom-with-deep-reinforcement-learning">Learning When and Where to Zoom with Deep Reinforcement Learning</h2>
<blockquote>
<p>åˆ†ç±»ä»»åŠ¡ä¸­å­¦ä¹ å¦‚ä½•ç¼©æ”¾ï¼Œspatially-sample</p>
</blockquote>
<p><strong>Attention</strong>ï¼š<u>å…ˆLR</u>ç”¨saliency networkäº§ç”Ÿattention mapï¼Œç„¶å<u>æ˜ å°„</u>åˆ°HRå›¾ç‰‡ä¸Šä½¿ç”¨</p>
<p><img src="Figures/image-20200306005012796.png" alt="image-20200306005012796"></p>
<p>å­¦ä¹ ï¼šæ ¹æ®LRå›¾åƒå†³ç­–sampleå“ªäº›HRå›¾åƒã€‚sampleæˆæœ¬å’Œå‡†ç¡®ç‡tradeoff</p>
<p><img src="Figures/image-20200306010155518.png" alt="image-20200306010155518"></p>
<ol>
<li>ğŸ‘†ç”±LRå›¾ç‰‡é€šè¿‡policy networkè®¡ç®—å‡ºéœ€è¦zoom-inçš„grid</li>
<li>ç›´æ¥åœ¨HRä¸Šç›´æ¥sampleç›¸åº”ä½ç½®ï¼Œæ„æˆpath</li>
<li>HR-patchå’ŒLRåŸå›¾ç‰‡(optional)è¾“å…¥åˆ†ç±»ç½‘ç»œåˆ†ç±»</li>
<li>åˆ†ç±»æŸå¤±rewardè¿”å›ç»™policy network</li>
</ol>
<p>é€‚ç”¨äºé¥æ„Ÿ/é«˜åˆ†è¾¨ç‡å›¾ç‰‡åˆ†ç±»/æ£€æµ‹(?)</p>
<hr>
<h3 id="jaccard-distance">Jaccard distance</h3>
<p>è¡¡é‡ä¸¤ä¸ªsetä¹‹é—´çš„è·ç¦»</p>
<p><strong>Jaccard index</strong>: <img src="https://latex.codecogs.com/svg.latex?J%28X,Y%29=\frac{|X\cap%20Y|}{|X\cup%20Y|}" alt="latex_equ"></p>
<p><strong>Distance</strong>: <img src="https://latex.codecogs.com/svg.latex?D%28X,Y%29=1-J%28X,Y%29" alt="latex_equ"></p>
<p>Ref: <a href="https://www.statisticshowto.datasciencecentral.com/jaccard-index/">https://www.statisticshowto.datasciencecentral.com/jaccard-index/</a></p>
<hr>
<h3 id="label-smoothing">Label Smoothing</h3>
<p>é’ˆå¯¹æ•°æ®é›†ä¸­<strong>é”™è¯¯æ ‡æ³¨</strong>ï¼Œä½¿<code>[0, 1]</code>å˜æˆ<code>[0.2, 0.8]</code>ï¼Œå‡å¼±æ­£æ ·æœ¬çš„lossï¼Œå†²æ·¡é”™è¯¯ä¿¡å·çš„å½±å“</p>
<p><img src="https://latex.codecogs.com/svg.latex?new\_onehot\_labels%20=%20labels%20*%20%281%20-%20label\_smoothing%29%20+%20label\_smoothing%20*%20\frac{1}{|labels|}" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?new\_label=[0\;1]\times%281-0.2%29+0.2\times%20\frac{1}{2}=[0.1\;0.9]" alt="latex_equ"></p>
<blockquote>
<p>Large logit gaps combined with the bounded gradient will make the model less adaptive and too confident about its predictions.</p>
</blockquote>
<hr>
<h2 id="bidet-an-efficient-binarized-object-detector">BiDet: An Efficient Binarized Object Detector</h2>
<blockquote>
<p>äºŒå€¼ç¥ç»ç½‘ç»œï¼Œä½¿ç”¨Information Bottleneckç†è®ºç®€åŒ–ç½‘ç»œ(ä½œä¸ºä¸€ä¸ªæŸå¤±å‡½æ•°)</p>
</blockquote>
<p>æ£€æµ‹ä»»åŠ¡çœ‹ä½œ<img src="https://latex.codecogs.com/svg.latex?X\to%20F\to%20L,C" alt="latex_equ">ï¼Œå›¾ç‰‡åˆ°ç‰¹å¾åˆ°ç±»åˆ«ä½ç½®</p>
<p><strong>Information Bottleneckç†è®º</strong></p>
<p>ç›®æ ‡ä¸º<img src="https://latex.codecogs.com/svg.latex?\min%20_{\phi_{b},%20\phi_{d}}%20I%28X%20;%20F%29-\beta%20I%28F%20;%20C,%20L%29" alt="latex_equ"></p>
<p>æœ€å°åŒ–ç‰¹å¾æå–çš„äº’ä¿¡æ¯ï¼ˆä¿¡æ¯å¢ç›Šï¼ŒçŸ¥é“Aå¯¹ç¡®å®šBçš„å½±å“ï¼‰ï¼Œæœ€å¤§åŒ–æ£€æµ‹ç½‘ç»œçš„äº’ä¿¡æ¯</p>
<p><em>äº’ä¿¡æ¯å¯ä»¥çœ‹ä½œç½‘ç»œçš„ä¿¡æ¯æŸå¤±ï¼Œäº’ä¿¡æ¯å¤§ï¼Œä¿¡æ¯æŸå¤±å¤§ã€‚å‰åŠéƒ¨åˆ†ä¸ºç½‘ç»œæå–è¶³å¤Ÿçš„ç‰¹å¾ï¼ŒååŠéƒ¨åˆ†ä¸ºåªæ£€æµ‹æœ‰æ•ˆçš„æ¡†ï¼Œå»é™¤å†—ä½™ä¿¡æ¯</em></p>
<p><strong>æŸå¤±å‡½æ•°</strong>ï¼š<img src="https://latex.codecogs.com/svg.latex?\begin{aligned}%20&amp;\min%20J=J_{1}+J_{2}\\%20&amp;\begin{aligned}%20=&amp;\left%28\sum_{t,%20s}%20\log%20\frac{p\left%28f_{s%20t}%20|%20\boldsymbol{x}\right%29}{p\left%28f_{s%20t}\right%29}-\beta%20\sum_{i=1}^{b}%20\log%20\frac{p\left%28c_{i}%20|%20\boldsymbol{f}\right%29%20p\left%28\boldsymbol{l}_{1,%20i}%20|%20\boldsymbol{f}\right%29%20p\left%28\boldsymbol{l}_{2,%20i}%20|%20\boldsymbol{f}\right%29}{p\left%28c_{i}\right%29%20p\left%28\boldsymbol{l}_{1,%20i}\right%29%20p\left%28\boldsymbol{l}_{2,%20i}\right%29}\right%29%20\\%20&amp;-\gamma%20\cdot%20\frac{1}{m}%20\sum_{i=1}^{m}%20s_{i}%20\log%20s_{i}%20\end{aligned}%20\end{aligned}" alt="latex_equ"></p>
<p>å…¶ä¸­<img src="https://latex.codecogs.com/svg.latex?J_1" alt="latex_equ">ä¸ºIBç†è®ºçš„ä¼˜åŒ–ç›®æ ‡ï¼Œç±»åˆ«å¤šé¡¹å¼åˆ†å¸ƒï¼Œä½ç½®æ­£æ€åˆ†å¸ƒï¼Œ<img src="https://latex.codecogs.com/svg.latex?p\left%28f_{s%20t}%20|%20\boldsymbol{x}\right%29" alt="latex_equ">é€šè¿‡é‡‡æ ·å¾—åˆ°</p>
<p><img src="https://latex.codecogs.com/svg.latex?J_2=-\gamma%20\cdot%20\frac{1}{m}%20\sum_{i=1}^{m}%20s_{i}%20\log%20s_{i}" alt="latex_equ">ä¸ºå‡å°‘ä¸€å¼ å›¾ä¸­ç›®æ ‡çš„è‡ªä¿¡æ¯(<img src="https://latex.codecogs.com/svg.latex?s_i" alt="latex_equ">ä¸ºç¬¬iä¸ªç‰©ä½“çš„objectness)ã€‚æŠŠä¸€å¼ å›¾çš„å¤šä¸ªç‰©ä½“åˆ†ä¸ºå¤šä¸ªblockï¼Œä½¿<img src="https://latex.codecogs.com/svg.latex?\sum^{m}_{i}s_i=1" alt="latex_equ">ç›®æ ‡confå’Œä¸º1ï¼Œå‡å°‘ç›®æ ‡æ•°é‡/å‡é˜³æ€§ï¼Œå³è®©ä¸€å¼ å›¾å†…ä¸è¦æœ‰å¤šä¸ªhigh objectnessçš„ç‰©ä½“ï¼Œé™åˆ¶ä¸ºåªæœ‰å°‘é‡ç‰©ä½“ã€Œ<u>é€‚ç”¨äºæ¯å¼ ç…§ç‰‡ç›®æ ‡è¾ƒå°‘çš„æ•°æ®é›†</u>ã€</p>
<hr>
<h2 id="mixup-beyond-empirical-risk-minimization">Mixup: Beyond Empirical Risk Minimization</h2>
<p>å¸¸è§ç½‘ç»œè®­ç»ƒä¸º<strong>ERM</strong>ï¼šè®­ç»ƒæ•°æ®ä¸ºç»éªŒï¼Œè®°ä½æ‰€æœ‰æ ·æœ¬ï¼Œä¸èƒ½<u>æ³›åŒ–</u></p>
<p>æ•°æ®å¢å¼ºå¯ä»¥ç†è§£ä¸º<strong>VRM (vicinal risk minimization)</strong>ï¼šé¢†åŸŸé£é™©æœ€å°åŒ–ï¼Œæ„é€ æ•°æ®é›†æ ·æœ¬çš„é¢†åŸŸå€¼ï¼Œå­¦ä¹ é¢†åŸŸçš„å°å˜åŒ–ï¼Œä½†æ–¹å¼<u>dataset-dependent&amp;heuristic</u></p>
<p>æå‡ºåˆ©ç”¨çº¿æ€§æ’å€¼äº§ç”Ÿæ–°çš„æ ‡æ³¨æ ·æœ¬å¯¹ï¼Œæ··åˆåˆ°æ•°æ®é›†ä¸­è®­ç»ƒã€Œå¢åŠ æœ‰å™ªå£°çš„æ ·æœ¬ã€</p>
<p><img src="https://latex.codecogs.com/svg.latex?\tilde{x}=\lambda%20x_i+%281-\lambda%29x_j" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?\tilde{y}=\lambda%20y_i+%281-\lambda%29y_j" alt="latex_equ"></p>
<p>å…¶ä¸­<img src="https://latex.codecogs.com/svg.latex?%28x_i,y_i%29" alt="latex_equ">å’Œ<img src="https://latex.codecogs.com/svg.latex?%28x_j,y_j%29" alt="latex_equ">ä¸ºæ•°æ®é›†ä¸­ã€Œæ ‡æ³¨-æ ·æœ¬ã€å¯¹ï¼Œ<img src="https://latex.codecogs.com/svg.latex?\lambda\in%20[0,1]" alt="latex_equ"></p>
<hr>
<h2 id="hybrid-task-cascade-for-instance-segmentation">Hybrid Task Cascade for Instance Segmentation</h2>
<blockquote>
<p>å®ä¾‹åˆ†å‰²ï¼Œçº§è”ï¼Œmaskå’ŒboxåŒæ—¶é‡‡ç”¨cascadeæ–¹å¼refine</p>
</blockquote>
<p><img src="Figures/image-20200321232008290.png" alt="image-20200321232008290"></p>
<p>ğŸ‘†çº§è”refineï¼Œboxå’Œmaskä¸¤ä¸ªåˆ†æ”¯ã€‚æ¥å—ä¸Šä¸€stageå›å½’åçš„boxä½œä¸ºè¾“å…¥ï¼Œé¢„æµ‹æ–°çš„maskå’Œbox</p>
<p><img src="Figures/image-20200321232235092.png" alt="image-20200321232235092"></p>
<p>ğŸ‘†mask1æ˜¯box1ç»è¿‡poolä¹‹åå¾—åˆ°çš„ï¼Œmaskå’Œboxä¸¤ä¸ªåˆ†æ”¯æœ‰äº¤äº’ï¼Œbox<img src="https://latex.codecogs.com/svg.latex?\to" alt="latex_equ">mask</p>
<p><img src="Figures/image-20200321232338714.png" alt="image-20200321232338714"></p>
<p>ğŸ‘†maskä¹‹é—´ä¹Ÿè¿›è¡Œä¿¡æ¯äº¤äº’</p>
<p><img src="Figures/image-20200321232559233.png" alt="image-20200321232559233"></p>
<p>äº¤äº’æ–¹å¼ğŸ‘†ï¼Œä¸Šä¸€ä¸ªstageçš„maskç»è¿‡<code>1x1</code> convï¼Œç„¶åå’Œbox_poolç›¸åŠ ï¼Œä¸Šä¸€ä¸ªstageçš„maskå’Œboxå…±åŒäº§ç”Ÿä¸‹ä¸€ä¸ªstageçš„mask</p>
<p><img src="Figures/image-20200321232644137.png" alt="image-20200321232644137"></p>
<p>ğŸ‘†æœ€ååŠ å…¥è¯­ä¹‰ä¿¡æ¯åˆ†æ”¯</p>
<p>æ€§èƒ½æå¼ºï¼Œé€Ÿåº¦æ…¢ğŸ‘‡</p>
<p><img src="Figures/image-20200321232902678.png" alt="image-20200321232902678"></p>
<p><img src="Figures/image-20200321233013589.png" alt="image-20200321233013589"></p>
<hr>
<h2 id="-">æ¨¡å‹é›†æˆ/é›†æˆå­¦ä¹ </h2>
<p>å¤šä¸ªå¼±å­¦ä¹ å™¨é›†æˆç»„åˆä¸ºæ›´ç²¾ç¡®æ›´é²æ£’æ¨¡å‹</p>
<p>å•ä¸ªæ¨¡å‹ æˆ–ä¸ºé«˜åç½®ï¼ˆä½è‡ªç”±åº¦æ¨¡å‹ï¼‰ï¼Œæˆ–ä¸ºé«˜æ–¹å·®ï¼ˆé«˜è‡ªç”±åº¦æ¨¡å‹ï¼‰ã€‚æ ¹æ®å¼±å­¦ä¹ å™¨çš„æ€§èƒ½é€‰æ‹©é›†æˆæ–¹æ³•ï¼Œé«˜åç½®ä½¿ç”¨<code>compose</code>ï¼Œé«˜æ–¹å·®ä½¿ç”¨<code>average</code></p>
<p><img src="Figures/640.png" alt="img"></p>
<h4 id="bagging-bootstrap-aggregating-">Bagging (bootstrap+aggregating)</h4>
<p>å¹¶è¡Œçš„ç‹¬ç«‹å­¦ä¹ å¤šä¸ªåŒè´¨å¼±å­¦ä¹ å™¨ï¼Œç›®æ ‡ä¸º<strong>å‡å°æ–¹å·®</strong></p>
<ol>
<li>ä½¿ç”¨bootstrapæ–¹æ³•ä»æºæ•°æ®é›†å–æ ·Nä¸ªæ•°æ®é›†ï¼Œè®¡ç®—ç»Ÿè®¡é‡ã€Œç½®ä¿¡åº¦ï¼Œrepresentative samplesã€</li>
<li>ä½¿ç”¨Nä¸ªæ•°æ®é›†ç‹¬ç«‹è®­ç»ƒNä¸ªå¼±å­¦ä¹ å™¨</li>
<li>æœ€ç»ˆç»“æœç”±Nä¸ªæ¨¡å‹çš„é¢„æµ‹æŠ•ç¥¨å¾—åˆ°</li>
</ol>
<p>å¦‚ï¼šéšæœºæ£®æ—</p>
<h4 id="boosting">Boosting</h4>
<p>è¿­ä»£çš„æ‹Ÿåˆæ¨¡å‹ï¼Œä¸²è¡Œï¼Œç›®æ ‡ä¸º<strong>å‡å°åç½®</strong></p>
<ol>
<li>è®­ç»ƒé›†æˆå­¦ä¹ å™¨</li>
<li>reweightæ•°æ®é›†ã€Œå…³æ³¨éš¾æ ·æœ¬ã€</li>
<li>åŠ å…¥æ–°çš„å¼±å­¦ä¹ å™¨<img src="https://latex.codecogs.com/svg.latex?s_{l}%28.%29=s_{l-1}%28.%29+c_{l}%20\times%20w_{l}%28.%29" alt="latex_equ"> ã€ŒAdaBoostæƒé‡ä¸º<img src="https://latex.codecogs.com/svg.latex?\arg\min\limits_{C_i}%20Error" alt="latex_equ"> æ€§èƒ½è¶Šå¥½è´¡çŒ®è¶Šå¤§ã€</li>
</ol>
<p><img src="Figures/640-20200411154812850.png" alt="img"></p>
<p>å¦‚ï¼šAdaBoostï¼ŒGBDT</p>
<h4 id="stacking">Stacking</h4>
<p>å¤šä¸ªå¼±å­¦ä¹ å™¨å †å ï¼Œå­¦ä¹ å…ƒæ¨¡å‹å°†å…¶ç»„åˆã€Œä¾‹å¦‚ï¼šKNN+Logistic-Reg+SVMï¼ŒNNå°†å…¶ç»„åˆã€</p>
<ol>
<li>è®­ç»ƒæ•°æ®é›†åˆ†ä¸ºä¸¤ç»„</li>
<li>ç¬¬ä¸€ç»„è®­ç»ƒæ‹Ÿåˆå¼±å­¦ä¹ å™¨</li>
<li>å¼±å­¦ä¹ å™¨åœ¨ç¬¬äºŒç»„ä¸Šçš„é¢„æµ‹ï¼Œä½œä¸ºå…ƒæ¨¡å‹çš„è¾“å…¥ã€‚åœ¨ç¬¬äºŒç»„æ•°æ®é›†ä¸Šæ‹Ÿåˆå…ƒæ¨¡å‹</li>
</ol>
<p><img src="Figures/640-20200411155054069.png" alt="img"></p>
<p>Ref: <a href="https://www.jiqizhixin.com/articles/2019-05-15-15">https://www.jiqizhixin.com/articles/2019-05-15-15</a>, <a href="https://zhuanlan.zhihu.com/p/27689464">https://zhuanlan.zhihu.com/p/27689464</a></p>
<hr>
<h2 id="improving-convolutional-networks-with-self-calibrated-convolutions-sc-conv-scnet-">Improving Convolutional Networks with Self-Calibrated Convolutions (SC Conv / SCNet)</h2>
<blockquote>
<p>åœ¨ Group ConvåŸºç¡€ä¸Šæ”¹è¿›å·ç§¯ heterogeneous</p>
<p>æ‹†åˆ†ä¸ºä¸è§„åˆ™çš„æ“ä½œ</p>
<p>å¢å¤§æ„Ÿå—é‡ï¼Œå¤§èŒƒå›´çš„context</p>
</blockquote>
<p><img src="Figures/image-20200512102143071.png" alt="image-20200512102143071"></p>
<p>é¦–å…ˆæŠŠåŸå§‹ç‰¹å¾å›¾<u>é€šé“ä¸Š</u>åˆ†ä¸ºä¸¤éƒ¨åˆ† <code>Group Conv</code></p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathbf{X_1}" alt="latex_equ">ä¸º<strong>Self-Calibration</strong>åˆ†æ”¯ï¼Œ<img src="https://latex.codecogs.com/svg.latex?\mathbf{X_2}" alt="latex_equ">ä¸ºå·ç§¯åˆ†æ”¯</p>
<h4 id="self-calibration">Self-Calibration</h4>
<p>åˆ†åˆ«åœ¨small scaleçš„<code>latent</code>ç©ºé—´å’Œlarge scaleçš„<code>original</code>ç©ºé—´è¿›è¡Œå·ç§¯æ“ä½œï¼Œå†èåˆ<code>calibration</code></p>
<p><strong>Latentç©ºé—´</strong>ï¼š</p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathbf{T}_{1}=\operatorname{AvgPool}_{r}\left%28\mathbf{X}_{1}\right%29" alt="latex_equ"> ä¸‹é‡‡æ ·å‡å°å°ºåº¦</p>
<p><img src="https://latex.codecogs.com/svg.latex?\mathbf{X}_{1}^{\prime}=\operatorname{Up}\left%28\mathcal{F}_{2}\left%28\mathbf{T}_{1}\right%29\right%29=\mathrm{Up}\left%28\mathbf{T}_{1}%20*%20\mathbf{K}_{2}\right%29" alt="latex_equ"> å°å°ºåº¦ä¸Šå·ç§¯å¹¶upsampleå›åŸå°ºåº¦</p>
<p><strong>Originalç©ºé—´å’Œlatentç©ºé—´èåˆ</strong>ï¼š<img src="https://latex.codecogs.com/svg.latex?\mathbf{Y}_{1}^{\prime}=\mathcal{F}_{3}\left%28\mathbf{X}_{1}\right%29%20\cdot%20\sigma\left%28\mathbf{X}_{1}+\mathbf{X}_{1}^{\prime}\right%29" alt="latex_equ"></p>
<p><img src="https://latex.codecogs.com/svg.latex?\sigma" alt="latex_equ"> for sigmoid function</p>
<p><strong>Final output</strong>ï¼š<img src="https://latex.codecogs.com/svg.latex?\mathbf{Y}_{1}=\mathcal{F}_{4}\left%28\mathbf{Y}_{1}^{\prime}\right%29=\mathbf{Y}^{\prime}%20*%20\mathbf{K_4}" alt="latex_equ"></p>
<p>Self-calibrationåœ¨å°å°ºåº¦æ“ä½œï¼Œå¯ä»¥æ‰©å¤§æ„Ÿå—é‡ (<em>Regional context</em>)ï¼Œèåˆå¤šå°ºåº¦çš„ä¿¡æ¯</p>
<p><img src="Figures/image-20200512103726329.png" alt="image-20200512103726329"></p>
<hr>
<h2 id="strip-pooling-rethinking-spatial-pooling-for-scene-parsing">Strip Pooling: Rethinking Spatial Pooling for Scene Parsing</h2>
<blockquote>
<p>å¸¦çŠ¶poolingï¼Œå„å‘å¼‚æ€§ç‰¹å¾ï¼Œåˆ†å‰²ä»»åŠ¡</p>
</blockquote>
<p><img src="Figures/image-20200530103440982.png" alt="image-20200530103440982"></p>
<p>é•¿æ¡å½¢æ„Ÿå—é‡ï¼Œ&lt;font color=#FF0000 &gt;è¡Œæ„Ÿå—é‡&lt;/font&gt;åœ¨æ¯ä¸€è¡Œçš„æ‰€æœ‰åˆ—è¿›è¡Œaverageï¼Œ<u>å‹ç¼©åˆ°1åˆ—</u>ï¼Œpoolingç»“æœä¸ºåˆ—å‘é‡ï¼›&lt;font color=#0000FF &gt;åˆ—æ„Ÿå—é‡&lt;/font&gt;åœ¨æ¯ä¸€åˆ—çš„æ‰€æœ‰è¡Œaverageï¼Œ<u>å‹ç¼©åˆ°ä¸€è¡Œ</u>ï¼Œpoolingç»“æœä¸ºè¡Œå‘é‡</p>
<p>ç„¶åæ‰©å±•æˆåŸå›¾å°ºå¯¸ï¼Œå†fusion</p>
<p>å¯¹é•¿æ¡çŠ¶ç‰©ä½“åˆå¸®åŠ©ï¼Œå¯ä»¥é›†åˆä»»æ„ä¸¤ä¸ªä½ç½®çš„dependency (long-range)</p>
<p><img src="Figures/image-20200530104233646.png" alt="image-20200530104233646"></p>
<p><img src="Figures/image-20200530104306845.png" alt="image-20200530104306845"></p>
<hr>
<h2 id="res2net-a-new-multi-scale-backbone-architecture">Res2Net: A New Multi-scale Backbone Architecture</h2>
<blockquote>
<p>å¤šå°ºåº¦å·ç§¯ï¼Œé€šç”¨ï¼Œä½†é€Ÿåº¦æœ‰ä¸‹é™ï¼›åŸºäºResNetï¼Œå¯ç”¨äºResNeXt</p>
</blockquote>
<p>å°†ä¸€ä¸ªå·ç§¯åˆ†æˆä¸åŒæ·±åº¦çš„æ“ä½œï¼Œè·å¾—ä¸åŒå°ºåº¦çš„ç©ºé—´/è¯­ä¹‰ä¿¡æ¯</p>
<p><img src="Figures/image-20200530113431833.png" alt="image-20200530113431833"></p>
<p>ç›¸æ¯”ResNetï¼Œå‡å°‘å‚æ•°é‡ææ€§èƒ½ã€‚åŒæ ·GFLOPSï¼Œé€Ÿåº¦ä¼šæ…¢ï¼Œä½†ç²¾åº¦æ›´é«˜ï¼›åŒæ ·ç²¾åº¦ä¸‹ï¼Œé€Ÿåº¦æ›´å¿«ã€‚</p>
<p><img src="Figures/image-20200530113939005.png" alt="image-20200530113939005"></p>
<hr>
